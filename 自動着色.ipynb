{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自動着色"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.models import Model,Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, Dense, Input,MaxPooling2D,Lambda,Conv2DTranspose,Activation\n",
    "from keras.preprocessing.image import load_img, img_to_array,array_to_img,ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセット読み出し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'dataset'\n",
    "data_lists = glob.glob(os.path.join(data_path, '*jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットの分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_n_sample = math.floor(len(data_lists) * 0.1)\n",
    "test_n_sample = math.floor(len(data_lists) * 0.1)\n",
    "train_n_sample = len(data_lists) - val_n_sample - test_n_sample\n",
    "\n",
    "val_lists = data_lists[:val_n_sample]\n",
    "test_lists = data_lists[val_n_sample:val_n_sample + test_n_sample]\n",
    "train_lists = data_lists[val_n_sample + test_n_sample:val_n_sample + test_n_sample + train_n_sample]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGBをLABに変換する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "\n",
    "def rgb2lab(rgb):\n",
    "    assert rgb.dtype == 'uint8'\n",
    "    return cv2.cvtColor(rgb,cv2.COLOR_RGB2Lab)\n",
    "\n",
    "def lab2rgb(lab):\n",
    "    assert lab.dtype == 'uint8'\n",
    "    return cv2.cvtColor(lab,cv2.COLOR_Lab2RGB)\n",
    "\n",
    "def get__lab_from_data_list(data_list):\n",
    "    x_lab = []\n",
    "    for f in data_list:\n",
    "        rgb = img_to_array(load_img(f,target_size = (image_size,image_size))).astype(np.uint8)\n",
    "        lab = rgb2lab(rgb)\n",
    "        x_lab.append(lab)\n",
    "    return np.stack(x_lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 32)      320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 64)      18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 56, 56, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 256)       295168    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 56, 56, 128)       295040    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 112, 112, 64)      73792     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 224, 224, 32)      18464     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 224, 224, 2)       66        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 224, 224, 2)       0         \n",
      "=================================================================\n",
      "Total params: 775,202\n",
      "Trainable params: 775,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input = Input(shape=(image_size,image_size,1))\n",
    "\n",
    "#encoder\n",
    "e = Conv2D(32,3,strides = 1,padding='same')(input)\n",
    "e = Activation('relu')(e)\n",
    "e = Conv2D(64,3,strides = 2,padding='same')(e)\n",
    "e = Activation('relu')(e)\n",
    "e = Conv2D(128,3,strides = 2,padding='same')(e)\n",
    "e = Activation('relu')(e)\n",
    "e = Conv2D(256,3,strides = 2,padding='same')(e)\n",
    "e = Activation('relu')(e)\n",
    "\n",
    "#dncoder\n",
    "\n",
    "d = Conv2DTranspose(128,3,strides = 2,padding = 'same')(e)\n",
    "d = Activation('relu')(d)\n",
    "d = Conv2DTranspose(64,3,strides = 2,padding = 'same')(d)\n",
    "d = Activation('relu')(d)\n",
    "d = Conv2DTranspose(32,3,strides = 2,padding = 'same')(d)\n",
    "d = Activation('relu')(d)\n",
    "d = Conv2DTranspose(2,1,strides = 1,padding = 'same')(d)\n",
    "d = Activation('relu')(d)\n",
    "\n",
    "autoencoder = Model(inputs=input, outputs=d)\n",
    "autoencoder.compile(optimizer='adam', loss = 'mse')\n",
    "\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generator関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_with_preprocessing(data_list,batch_size,shuffle=False):\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            np.random.shuffle(data_list)\n",
    "        for i in range(0, len(data_list),batch_size):\n",
    "            batch_list = data_list[i:i + batch_size]\n",
    "            batch_lab = get__lab_from_data_list(batch_list)\n",
    "            batch_l = batch_lab[:,:,:,0:1]\n",
    "            batch_ab = batch_lab[:,:,:,1:]\n",
    "            yield(batch_l,batch_ab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### geneatorの呼び出し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 30\n",
    "\n",
    "train_gen = generator_with_preprocessing(train_lists,batch_size,shuffle=True)\n",
    "val_gen = generator_with_preprocessing(val_lists,batch_size,shuffle=False)\n",
    "test_gen = generator_with_preprocessing(test_lists,batch_size,shuffle=False)\n",
    "\n",
    "\n",
    "train_steps = math.ceil(len(train_lists)/batch_size)\n",
    "val_steps = math.ceil(len(val_lists)/batch_size)\n",
    "test_steps = math.ceil(len(test_lists)/batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  1/783 [..............................] - ETA: 4:03:02 - loss: 19055.5391"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "autoencoder.fit_generator(generator=train_gen,steps_per_epoch=train_steps,epochs = epochs,\n",
    "                          validation_data=val_gen,validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-9689841990b9>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-9689841990b9>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    x_test[]\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "preds = autoencoder.predict_generator(test_gen,steps=test_steps,verbose=0)\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for i,(l,ab) in enumerate(generator_with_preprocessing(test_lists,batch_size)):\n",
    "    x_test.append(l)\n",
    "    y_test.append(ab)\n",
    "    if i == (test_steps - 1):\n",
    "        break\n",
    "    \n",
    "x_test = np.vstack(x_test)\n",
    "y_test = np.vstack(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 予測結果をLABからRGBに変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_lab = np.concatenate((x_test,preds),3).astype(np.uint8)\n",
    "\n",
    "test_preds_lab.shape\n",
    "\n",
    "test_preds_rgb = []\n",
    "for i in range(test_preds_lab.shape[0]):\n",
    "    preds_rgb = lab2rgb(test_preds_lab[i,:,:,:])\n",
    "    test_preds_rgb.append(preds_rgb)\n",
    "test_preds_rgb = np.stack(test_preds_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結果表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_png\n",
    "from PIL import Image,ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(test_preds_rgb.shape[0]):\n",
    "    gray_image = ImageOps.grayscale(array_to_img(test_preds_rgb[i]))\n",
    "#     display_png(array_to_img(test_lists[i]))\n",
    "    display_png(gray_image)\n",
    "    display_png(array_to_img(test_preds_rgb[i]))\n",
    "    print('-'*25)\n",
    "    if i == 5:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
